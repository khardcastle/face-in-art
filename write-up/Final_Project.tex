\documentclass{article}
\usepackage[final]{nips_2017}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\title{Make yourself into a work of art}

\author{
  Kiah Hardcastle* and Julie Makelberge** \\
  Neuroscience PhD Program*, Graduate School of Business** \\
  Stanford University\\
  \texttt{khardcas@stanford.edu*, juliemkb@stanford.edu**} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\begin{center}
\includegraphics[width=3cm, height=0.7cm]{CS230}
\end{center}

\maketitle

\begin{abstract}
In this paper, we present a method by which one can integrate a person's face into an artistic painting containing a face. For example, given a headshot and a picture of the Mona Lisa, this method will inpaint the face in the headshot photo into the face of the Mona Lisa, while retaining the artistic style of the Mona Lisa. To accomplish this task, we implemented two procedures: face-warping (to properly align the faces), and neural style transfer (to transfer the style of the painting to the headshot face). This approach builds on previous work in several ways. First, while there are a number of existing applications that have focused on face swapping in recent years, they have generally been applied to photograph images that have a similar style. Second, the few methodologies that have used neural style transfer combined with face-swapping have constrained their solution to well-aligned images that contain only a face (i.e., cropped images). In addition, these approaches have transfered the transfered the style of the artistic image to the headshot image, without putting the newly-styled headshot image into the artistic image. Thus, our approach is novel in that we aim to retain the style and pose of the original work of art's face, regardless of the pose of the supplied image, and  reintroduce the face in the work of art as a whole. 
\end{abstract}

\section{Introduction}  
The problem that we investigate in this project is how to inpaint a face from a photograph into the face in an artistic painting. Specifically, our framework takes two images: 1. a photograph image containing a face and 2. an artistic photo containing a face, and returns one image: a new version of the artistic photo with the face replaced. The replaced face is in the same pose, and in the same style, as the original artistic face, but the content of the face is drawn from the photographed face. To accomplish this task, we combine face-swapping with neural style transfer techniques. Our approach differs from traditional face-swapping methods in that it deal with images of fundamentally different style (artistic images versus photographs), and differs from traditional neural style transfer methods in that it requires face-swapping, and replaces a subset of the content (i.e. just the face) of the artistic image. However, our methods are similar in that our pipeline generates a new image - in other words, we use deep learning to generate personalized artwork. 

With the advent of neural style transfer in 2015 \cite{gatys2015neural}, and generative adversarial networks in 2014 \cite{gan2014}, generating artwork via neural networks has become a topic of high interest. For example, in October 2018 an AI-generated piece of artwork sold for nearly half a million dollars. Recently, AI-generated art was featured in art galleries in San Francisco ("DeepDream") and New York City ("Faceless Portraits Transcending Time"). While our method simply alters previous versions of artwork rather than generating a fundamentally new piece of art, it does so in a personalized manner.


\section{Related work}

Neural style transfer is the technique of using deep neural networks to transfer the style of a given reference image to the content of another. Traditionally, such problems have been adressed with classic image processing techniques such as histogram matching \cite{neumann2005color}. However, in 2015 Gatys et al. \cite{gatys2015neural} introduced a novel technique that leverages the power of Convolutional Neural Networks to emulate famous painting styles in natural images. In their seminal paper, they proposed to use the encoding from different layers of a pre-trained CNN, to capture the style elements and content elements of images. They then used an interative approach to optimise an image with the objective of minimizing the distance between the style elements of the image and the reference work of art, while keeping changes to the content as small as possible. 

Their work has inspired a number of new neural transfer algorithms, ranging from general models such as the work of Li and Wand \cite{li2016combining} that combined generative Markov random field models with deep convolutional neural networks, to highly specialised domain-specific models such as Jiang anf Fu's Fashion style generator \cite{jiang2017fashion}. While general models have shown great potential in a large number of applications, they have generally introduced visual artifacts which are especially striking in faces, given human's sensitivity for facial irregularities. The work of Selim et al. \cite{selim2016painting} introduced the first approach for single-example based head portrait painting not constrained to a specific style. Their approach was successful by introducing additional constraints that exploit human facial geometry through the notion of gains maps. However, their methodology focused on front-facing cropped facial images and does not yet generalise to different facial positions or introduction within the wider context of a full painting.

In this work, we aim to expand on the work of Selim et al by introducing a framework that combines different Neural Transfer techniques to tackle the challenge of introducing faces of slightly varing positions in a work of art. Our goal is to create a resulting image that looks similar to our reference work of art, but with the exception of having a different person in mind at the time of painting. This technique would be valuable in the world of generative art as it alows different and personalised renderings of the same types of art work. 

Add in description of complicated paper

Add in face warping methods (in Selim and also in opencv) and face rotation methods

\section{Dataset and Features}

Fortunately, as many of our methods will rely on pre-trained networks, we do not need large numbers of new images with which to train our network. However, there are large open-source datasets of artwork and faces available on the internet, which we plan to take advantage of in order to demonstrate our approach. To generate our dataset of artwork, we use the Web Gallery of Art \cite{WebGallery}. This dataset is free to use for educational purposes and contains the meta data and links to images for more than 45,000 works of art, 31,000 of which are paintings. In order to create the dataset, we wrote write a script to download these images (see github repo).  To generate a dataset of faces, we initially plan to use own headshots. However, we plan to use the celebA dataset \cite{liu2018large} if more face images are required.

Show some examples
give the resolution


\section{ Methods }

Solving this task requires solving several sub-problems: cropping faces, warping faces so that promiment landmarks are location-matched, performing neural style transfer in order to transfer the style of the artistic painting to the photographed face, and seamlessly replacing the face in the artistic painting with a new face. 

Describe your learning algorithms, proposed algorithm(s), or theoretical proof(s). Make
sure to include relevant mathematical notation. For example, you can include the loss function you are using. It is okay to use formulas from the lectures (online or in-class). For each algorithm, give a short description 
of how it works. Again, we are looking for your understanding of how these deep
learning algorithms work. Although the teaching staff probably know the algorithms, future
readers may not (reports will be posted on the class website). Additionally, if you are
using a niche or cutting-edge algorithm (anything else not covered in the class), you may want to explain your algorithm using 1/2
paragraphs. Note: Theory/algorithms projects may have an appendix showing extended
proofs (see Appendix section below).

\section{Experiments/Results/Discussion}

You should also give details about what (hyper)parameters you chose (e.g. why did you
use X learning rate for gradient descent, what was your mini-batch size and why) and how
you chose them. What your primary metrics are: accuracy, precision,
AUC, etc. Provide equations for the metrics if necessary. For results, you want to have a
mixture of tables and plots. If you are solving a classification problem, you should include a
confusion matrix or AUC/AUPRC curves. Include performance metrics such as precision,
recall, and accuracy. For regression problems, state the average error. You should have
both quantitative and qualitative results. To reiterate, you must have both quantitative
and qualitative results! If it applies: include visualizations of results, heatmaps,
examples of where your algorithm failed and a discussion of why certain algorithms failed
or succeeded. In addition, explain whether you think you have overfit to your training set
and what, if anything, you did to mitigate that. Make sure to discuss the figures/tables in
your main text throughout this section. Your plots should include legends, axis labels, and
have font sizes that are legible when printed.

\section{Conclusion/Future Work }
Summarize your report and reiterate key points. Which algorithms were the highestperforming?
Why do you think that some algorithms worked better than others? For
future work, if you had more time, more team members, or more computational resources,
what would you explore?

\section{Contributions}
The contributions section is not included in the 5 page limit. This section should describe
what each team member worked on and contributed to the project.

\section*{References}
This section should include citations for: (1) Any papers mentioned in the related work
section. (2) Papers describing algorithms that you used which were not covered in class.
(3) Code or libraries you downloaded and used. This includes libraries such as scikit-learn, Tensorflow, Pytorch, Keras etc. Acceptable formats include: MLA, APA, IEEE. If you
do not use one of these formats, each reference entry must include the following (preferably
in this order): author(s), title, conference/journal, publisher, year. If you are using TeX,
you can use any bibliography format which includes the items mentioned above. We are excluding
the references section from the page limit to encourage students to perform a thorough
literature review/related work section without being space-penalized if they include more
references. Any choice of citation style is acceptable
as long as you are consistent. 

\medskip
\small

\bibliography{References}
\bibliographystyle{plain}

\end{document}